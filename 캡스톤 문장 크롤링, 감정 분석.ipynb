{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (2.125.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.18.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í¬ë¡¤ë§í•œ ì‚¬ì´íŠ¸\n",
    "ìœ íŠœë¸Œ [ë­‰í´í•œ ì£¼ë§ğŸ¥° #13] ì„œìš¸ í•œë³µíŒì—ì„œ ëŠë¼ëŠ” ì´ì›ƒì˜ ë”°ëœ»í•œ ì • | í–‰ë³µì„ íŒŒëŠ” ê°€ê²Œ - êµ­ìˆ˜ í• ë§¤ì™€ êµ¬ë‘ í• ë°° [ë‹¤í ê³µê° | KBS 130924 ë°©ì†¡]<br>\n",
    "https://www.youtube.com/watch?v=S9lkaozex0w\n",
    "\n",
    "ğğ¥ğšğ²ğ¥ğ¢ğ¬ğ­ ê¸ì • ì—ë„ˆì§€ ë¿œì–´ë‚´ëŠ” ì¶œê·¼ê¸¸ ë…¸ë˜ ëª¨ìŒğŸ˜„ í–‰ë³µ ê°€ë“í•œ í•˜ë£¨ë¥¼ ìœ„í•œ í…ì…˜ ì—… í”Œë¦¬ğŸˆ<br>\n",
    "https://www.youtube.com/watch?v=PYUPmD7eQz0\n",
    "\n",
    "í˜ë“¤ê³  ì§€ì¹ ë•Œ ìœ„ë¡œê°€ ë˜ì–´ì£¼ëŠ” ë…¸ë˜<br>\n",
    "https://www.youtube.com/watch?v=5ebOrg5Njnc\n",
    "\n",
    "[Playlist] ê´œì°®ì•„, ë‹¤ ì˜ë ê±°ì•¼. í˜ë“¤ê³  ì§€ì¹œ ë‹¹ì‹ ì„ ìœ„ë¡œí•´ì£¼ëŠ” ë…¸ë˜ğŸµ<br>\n",
    "https://www.youtube.com/watch?v=uGa2cN1N5-Y\n",
    "\n",
    "ìì‹ ê°ì´ ì—†ì„ ë•Œ, í˜ë“¤ê³  ì§€ì¹  ë•Œ í˜ì´ ë˜ì–´ì£¼ëŠ” ë…¸ë˜ëª¨ìŒ<br>\n",
    "https://www.youtube.com/watch?v=C57eP02b5f4\n",
    "\n",
    "[ğğ¥ğšğ²ğ¥ğ¢ğ¬ğ­] ë‚˜ í˜ë“¤ì–´, ì•ˆì•„ì¤˜. ë‹¹ì‹ ì˜ ë§ˆìŒì„ ìœ„ë¡œí•˜ëŠ” í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ğŸ©¹<br>\n",
    "https://www.youtube.com/watch?v=ObY22aMUMxE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ íŠœë¸Œ ëŒ“ê¸€ í¬ë¡¤ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list()\n",
    "api_key = 'AIzaSyDXW9AQyXt8b7id6cDKI3VfjhW_QQeSttE' #ìœ íŠœë¸Œ ëŒ“ê¸€ í¬ë¡¤ë§ apií‚¤\n",
    "video_id = 'ObY22aMUMxE' #ìœ íŠœë¸Œ ì£¼ì†Œ ì¤‘ '=' ì´í›„ id\n",
    "api_obj = build('youtube', 'v3', developerKey=api_key)\n",
    "response = api_obj.commentThreads().list(part='snippet,replies', videoId=video_id, maxResults=100).execute()\n",
    "\n",
    "while response:\n",
    "    for item in response['items']:\n",
    "        comment = item['snippet']['topLevelComment']['snippet']\n",
    "        comments.append([comment['textDisplay'], comment['authorDisplayName'], comment['publishedAt'], comment['likeCount']])\n",
    " \n",
    "        if item['snippet']['totalReplyCount'] > 0:\n",
    "            for reply_item in item['replies']['comments']:\n",
    "                reply = reply_item['snippet']\n",
    "                comments.append([reply['textDisplay'], reply['authorDisplayName'], reply['publishedAt'], reply['likeCount']])\n",
    " \n",
    "    if 'nextPageToken' in response:\n",
    "        response = api_obj.commentThreads().list(part='snippet,replies', videoId=video_id, pageToken=response['nextPageToken'], maxResults=100).execute()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df = pandas.DataFrame(comments, columns=['comment', 'author', 'date', 'num_likes'])\n",
    "df.drop(columns=['author', 'date'], inplace=True)\n",
    "df.to_excel('ë¶€ì •4.xlsx', header=['comment', 'num_likes'], index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¬¸ì¥ í† í°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "def kor_token(comment):\n",
    "    okt = Okt()\n",
    "    token_words = okt.morphs(comment)\n",
    "    return token_words\n",
    "\n",
    "# add_token_result = ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì™€ ê° í–‰ì˜ ë¬¸ì¥ì„ í† í°í™”í•˜ê³  ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ ì—´ì— ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ \n",
    "def add_token_result(íŒŒì¼ê²½ë¡œ):\n",
    "    df_token = pd.read_excel(íŒŒì¼ê²½ë¡œ)\n",
    "    list_token = []\n",
    "    for index, row in df_token.iterrows():\n",
    "        comment = row['comment']  # 'comment' ì—´ì„ í† í°í™”\n",
    "        token_words = kor_token(comment)\n",
    "        list_token.append(token_words)\n",
    "    df_token['result_token'] = list_token\n",
    "    return df_token\n",
    "\n",
    "\n",
    "df_token = add_token_result(\"ë¶€ì •3.xlsx\")\n",
    "\n",
    "new = \"ë¶€ì •3í† í°í™”.xlsx\"\n",
    "df_token.to_excel(new, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•œê¸€ ê°ì„±ì–´ ì‚¬ì „(KNU) ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('SentiWord_info.json', encoding='utf-8-sig', mode='r') as f: \n",
    "  SentiWord_info = json.load(f)\n",
    "\n",
    "sentiword_dic = pd.DataFrame(SentiWord_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_excel('ë¶€ì •4í† í°í™”.xlsx')\n",
    "\n",
    "excel_list = new.iloc[:, 2].tolist()\n",
    "\n",
    "\n",
    "final = pd.DataFrame(columns=(\"comment\", \"sentiment\"))  # ìœ íŠœë¸Œ ëŒ“ê¸€ë³„ ê°ì • ì ìˆ˜ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "idx = 0                                             # ë‹¤ìŒ ëŒ“ê¸€ë¡œ ë„˜ê¸°ê¸° ìœ„í•œ ì´ˆê¸°ê°’\n",
    " \n",
    "for item in excel_list:                                # ì „ì²´ ëŒ“ê¸€ì—ì„œ ë¬¸ì¥ í•˜ë‚˜ì”© ê°€ì ¸ì˜´ \n",
    "  sentiment = 0                                     # ì´ˆê¸° ê°ì • ì ìˆ˜ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •\n",
    "  for i in range(0, len(sentiword_dic)):            # ê°ì„±ì‚¬ì „ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ì„ íƒ\n",
    "    if sentiword_dic.word[i] in item:              # ëŒ“ê¸€ ë¬¸ì¥ì— ê°ì„± ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "      sentiment += int(sentiword_dic.polarity[i])   # ê°ì„±ë‹¨ì–´ê°€ ìˆë‹¤ë©´ ê°ì • ì ìˆ˜ê°’ í•©ê³„ë¥¼ êµ¬í•¨.\n",
    "  final.loc[idx] = [item, sentiment]                  # ëŒ“ê¸€ë³„ ê°ì • ì ìˆ˜ê°’ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ìŒ“ìŒ\n",
    "  idx += 1\n",
    "\n",
    "final['original_comment'] = new.iloc[:, 0]  #ì›ë˜ ëŒ“ê¸€ ì¶”ê°€í•˜ê¸°\n",
    "\n",
    "final.to_excel(\"ë¶€ì •4ê²°ê³¼.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ëŸ°ì‹ìœ¼ë¡œ ëŒ“ê¸€ì„ ë¶„ì„í•œ í›„, ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ë§Œí•œ ë¬¸ì¥ë“¤ë§Œ ë¶„ë¥˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "ë§¤ìš° ê¸°ë¶„ ì¢‹ìŒ\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('SentiWord_info.json', encoding='utf-8-sig', mode='r') as f: \n",
    "  SentiWord_info = json.load(f)\n",
    "\n",
    "sentiword_dic = pd.DataFrame(SentiWord_info)\n",
    "\n",
    "# ë¬¸ì¥ì˜ ê°ì • ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "def sentiment_score(sentence):\n",
    "    sentiment = 0  # ì´ˆê¸° ê°ì • ì ìˆ˜ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •\n",
    "    for i in range(len(sentiword_dic[\"word\"])):  # ê°ì„±ì‚¬ì „ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ì„ íƒ\n",
    "        if sentiword_dic[\"word\"][i] in sentence:  # ì…ë ¥ ë¬¸ì¥ì— ê°ì„± ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "            sentiment += int(sentiword_dic[\"polarity\"][i])  # ê°ì„±ë‹¨ì–´ê°€ ìˆë‹¤ë©´ ê°ì • ì ìˆ˜ê°’ í•©ê³„ë¥¼ êµ¬í•¨\n",
    "    return sentiment\n",
    "\n",
    "# ì‚¬ìš©ìë¡œë¶€í„° ë¬¸ì¥ ì…ë ¥ ë°›ê¸°\n",
    "sentence = input(\"ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "\n",
    "# ì…ë ¥ ë°›ì€ ë¬¸ì¥ì˜ ê°ì • ì ìˆ˜ ê³„ì‚°\n",
    "score = sentiment_score(sentence)\n",
    "print(score)\n",
    "\n",
    "if score >= 10:\n",
    "    print(\"ë§¤ìš° ê¸°ë¶„ ì¢‹ìŒ\")\n",
    "elif 5 <= score < 10:\n",
    "    print(\"ê¸°ë¶„ ì¢‹ìŒ\")\n",
    "elif 0 <= score < 5:\n",
    "    print(\"ë³´í†µ\")\n",
    "elif -5 <= score < 0:\n",
    "    print(\"ê¸°ë¶„ ì•ˆì¢‹ìŒ\")\n",
    "else:  # score < -5\n",
    "    print(\"ë§¤ìš° ê¸°ë¶„ ì•ˆì¢‹ìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜ë”°ë¼ ë°˜ì§ì´ëŠ” ëˆˆì´ ì˜ˆì˜ë‹¤. í–‰ë³µí•œ ì¼ì´ ì¡°ê¸ˆì”© ìˆì—ˆë‚˜ë´! ì •ë§ ë‹¤í–‰ì´ê³  ì¶•í•˜í•´!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#ê°ì •ë‹µë³€\n",
    "df = pd.read_csv('https://github.com/HMinjae/heartfelt_project/raw/main/%EA%B0%90%EC%A0%95%EB%8B%B5%EB%B3%80.csv')  \n",
    "\n",
    "if score >= 10:\n",
    "    print(random.choice(df.iloc[:, 0].dropna().tolist()))\n",
    "elif 5 <= score < 10:\n",
    "    print(random.choice(df.iloc[:, 1].dropna().tolist()))\n",
    "elif 0 <= score < 5:\n",
    "    print(random.choice(df.iloc[:, 2].dropna().tolist()))\n",
    "elif -5 <= score < 0:\n",
    "    print(random.choice(df.iloc[:, 3].dropna().tolist()))\n",
    "else:\n",
    "    print(random.choice(df.iloc[:, 4].dropna().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future - Mask Off\n"
     ]
    }
   ],
   "source": [
    "#ë…¸ë˜ì¶”ì²œ\n",
    "df = pd.read_csv('ë…¸ë˜ì¶”ì²œ.csv')  \n",
    "if score >= 10:\n",
    "    print(random.choice(df.iloc[:, 0].dropna().tolist()))\n",
    "elif 5 <= score < 10:\n",
    "    print(random.choice(df.iloc[:, 1].dropna().tolist()))\n",
    "elif 0 <= score < 5:\n",
    "    print(random.choice(df.iloc[:, 2].dropna().tolist()))\n",
    "elif -5 <= score < 0:\n",
    "    print(random.choice(df.iloc[:, 3].dropna().tolist()))\n",
    "else:\n",
    "    print(random.choice(df.iloc[:, 4].dropna().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D ëª¨ë¸ë§ ë°°ìš°ê¸°\n"
     ]
    }
   ],
   "source": [
    "#í–‰ë™ì¶”ì²œ\n",
    "df = pd.read_csv('í–‰ë™ì¶”ì²œ.csv')  \n",
    "if score >= 0:\n",
    "    print(random.choice(df.iloc[:, 0].dropna().tolist()))\n",
    "else:\n",
    "    print(random.choice(df.iloc[:, 4].dropna().tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
