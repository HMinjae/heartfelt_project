{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (2.125.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.18.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hmj01\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링한 사이트\n",
    "유튜브 [뭉클한 주말🥰 #13] 서울 한복판에서 느끼는 이웃의 따뜻한 정 | 행복을 파는 가게 - 국수 할매와 구두 할배 [다큐 공감 | KBS 130924 방송]<br>\n",
    "https://www.youtube.com/watch?v=S9lkaozex0w\n",
    "\n",
    "𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭 긍정 에너지 뿜어내는 출근길 노래 모음😄 행복 가득한 하루를 위한 텐션 업 플리🎈<br>\n",
    "https://www.youtube.com/watch?v=PYUPmD7eQz0\n",
    "\n",
    "힘들고 지칠때 위로가 되어주는 노래<br>\n",
    "https://www.youtube.com/watch?v=5ebOrg5Njnc\n",
    "\n",
    "[Playlist] 괜찮아, 다 잘될거야. 힘들고 지친 당신을 위로해주는 노래🎵<br>\n",
    "https://www.youtube.com/watch?v=uGa2cN1N5-Y\n",
    "\n",
    "자신감이 없을 때, 힘들고 지칠 때 힘이 되어주는 노래모음<br>\n",
    "https://www.youtube.com/watch?v=C57eP02b5f4\n",
    "\n",
    "[𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭] 나 힘들어, 안아줘. 당신의 마음을 위로하는 플레이리스트🩹<br>\n",
    "https://www.youtube.com/watch?v=ObY22aMUMxE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유튜브 댓글 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list()\n",
    "api_key = 'AIzaSyDXW9AQyXt8b7id6cDKI3VfjhW_QQeSttE' #유튜브 댓글 크롤링 api키\n",
    "video_id = 'ObY22aMUMxE' #유튜브 주소 중 '=' 이후 id\n",
    "api_obj = build('youtube', 'v3', developerKey=api_key)\n",
    "response = api_obj.commentThreads().list(part='snippet,replies', videoId=video_id, maxResults=100).execute()\n",
    "\n",
    "while response:\n",
    "    for item in response['items']:\n",
    "        comment = item['snippet']['topLevelComment']['snippet']\n",
    "        comments.append([comment['textDisplay'], comment['authorDisplayName'], comment['publishedAt'], comment['likeCount']])\n",
    " \n",
    "        if item['snippet']['totalReplyCount'] > 0:\n",
    "            for reply_item in item['replies']['comments']:\n",
    "                reply = reply_item['snippet']\n",
    "                comments.append([reply['textDisplay'], reply['authorDisplayName'], reply['publishedAt'], reply['likeCount']])\n",
    " \n",
    "    if 'nextPageToken' in response:\n",
    "        response = api_obj.commentThreads().list(part='snippet,replies', videoId=video_id, pageToken=response['nextPageToken'], maxResults=100).execute()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df = pandas.DataFrame(comments, columns=['comment', 'author', 'date', 'num_likes'])\n",
    "df.drop(columns=['author', 'date'], inplace=True)\n",
    "df.to_excel('부정4.xlsx', header=['comment', 'num_likes'], index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "def kor_token(comment):\n",
    "    okt = Okt()\n",
    "    token_words = okt.morphs(comment)\n",
    "    return token_words\n",
    "\n",
    "# add_token_result = 엑셀 파일을 읽어와 각 행의 문장을 토큰화하고 결과를 새로운 열에 추가하여 반환하는 함수 \n",
    "def add_token_result(파일경로):\n",
    "    df_token = pd.read_excel(파일경로)\n",
    "    list_token = []\n",
    "    for index, row in df_token.iterrows():\n",
    "        comment = row['comment']  # 'comment' 열을 토큰화\n",
    "        token_words = kor_token(comment)\n",
    "        list_token.append(token_words)\n",
    "    df_token['result_token'] = list_token\n",
    "    return df_token\n",
    "\n",
    "\n",
    "df_token = add_token_result(\"부정3.xlsx\")\n",
    "\n",
    "new = \"부정3토큰화.xlsx\"\n",
    "df_token.to_excel(new, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 감성어 사전(KNU) 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('SentiWord_info.json', encoding='utf-8-sig', mode='r') as f: \n",
    "  SentiWord_info = json.load(f)\n",
    "\n",
    "sentiword_dic = pd.DataFrame(SentiWord_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_excel('부정4토큰화.xlsx')\n",
    "\n",
    "excel_list = new.iloc[:, 2].tolist()\n",
    "\n",
    "\n",
    "final = pd.DataFrame(columns=(\"comment\", \"sentiment\"))  # 유튜브 댓글별 감정 점수를 저장하기 위한 데이터프레임 생성\n",
    "idx = 0                                             # 다음 댓글로 넘기기 위한 초기값\n",
    " \n",
    "for item in excel_list:                                # 전체 댓글에서 문장 하나씩 가져옴 \n",
    "  sentiment = 0                                     # 초기 감정 점수값을 0으로 설정\n",
    "  for i in range(0, len(sentiword_dic)):            # 감성사전의 모든 단어를 하나씩 선택\n",
    "    if sentiword_dic.word[i] in item:              # 댓글 문장에 감성 단어가 있는지 확인\n",
    "      sentiment += int(sentiword_dic.polarity[i])   # 감성단어가 있다면 감정 점수값 합계를 구함.\n",
    "  final.loc[idx] = [item, sentiment]                  # 댓글별 감정 점수값을 데이터프레임으로 쌓음\n",
    "  idx += 1\n",
    "\n",
    "final['original_comment'] = new.iloc[:, 0]  #원래 댓글 추가하기\n",
    "\n",
    "final.to_excel(\"부정4결과.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런식으로 댓글을 분석한 후, 다양하게 사용할 수 있을만한 문장들만 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "매우 기분 좋음\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('SentiWord_info.json', encoding='utf-8-sig', mode='r') as f: \n",
    "  SentiWord_info = json.load(f)\n",
    "\n",
    "sentiword_dic = pd.DataFrame(SentiWord_info)\n",
    "\n",
    "# 문장의 감정 점수를 계산하는 함수\n",
    "def sentiment_score(sentence):\n",
    "    sentiment = 0  # 초기 감정 점수값을 0으로 설정\n",
    "    for i in range(len(sentiword_dic[\"word\"])):  # 감성사전의 모든 단어를 하나씩 선택\n",
    "        if sentiword_dic[\"word\"][i] in sentence:  # 입력 문장에 감성 단어가 있는지 확인\n",
    "            sentiment += int(sentiword_dic[\"polarity\"][i])  # 감성단어가 있다면 감정 점수값 합계를 구함\n",
    "    return sentiment\n",
    "\n",
    "# 사용자로부터 문장 입력 받기\n",
    "sentence = input(\"문장을 입력하세요: \")\n",
    "\n",
    "# 입력 받은 문장의 감정 점수 계산\n",
    "score = sentiment_score(sentence)\n",
    "print(score)\n",
    "\n",
    "if score >= 10:\n",
    "    print(\"매우 기분 좋음\")\n",
    "elif 5 <= score < 10:\n",
    "    print(\"기분 좋음\")\n",
    "elif 0 <= score < 5:\n",
    "    print(\"보통\")\n",
    "elif -5 <= score < 0:\n",
    "    print(\"기분 안좋음\")\n",
    "else:  # score < -5\n",
    "    print(\"매우 기분 안좋음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘따라 반짝이는 눈이 예쁘다. 행복한 일이 조금씩 있었나봐! 정말 다행이고 축하해!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#감정답변\n",
    "df = pd.read_csv('https://github.com/HMinjae/heartfelt_project/raw/main/%EA%B0%90%EC%A0%95%EB%8B%B5%EB%B3%80.csv')  \n",
    "\n",
    "if score >= 10:\n",
    "    print(random.choice(df.iloc[:, 0].dropna().tolist()))\n",
    "elif 5 <= score < 10:\n",
    "    print(random.choice(df.iloc[:, 1].dropna().tolist()))\n",
    "elif 0 <= score < 5:\n",
    "    print(random.choice(df.iloc[:, 2].dropna().tolist()))\n",
    "elif -5 <= score < 0:\n",
    "    print(random.choice(df.iloc[:, 3].dropna().tolist()))\n",
    "else:\n",
    "    print(random.choice(df.iloc[:, 4].dropna().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future - Mask Off\n"
     ]
    }
   ],
   "source": [
    "#노래추천\n",
    "df = pd.read_csv('노래추천.csv')  \n",
    "if score >= 10:\n",
    "    print(random.choice(df.iloc[:, 0].dropna().tolist()))\n",
    "elif 5 <= score < 10:\n",
    "    print(random.choice(df.iloc[:, 1].dropna().tolist()))\n",
    "elif 0 <= score < 5:\n",
    "    print(random.choice(df.iloc[:, 2].dropna().tolist()))\n",
    "elif -5 <= score < 0:\n",
    "    print(random.choice(df.iloc[:, 3].dropna().tolist()))\n",
    "else:\n",
    "    print(random.choice(df.iloc[:, 4].dropna().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D 모델링 배우기\n"
     ]
    }
   ],
   "source": [
    "#행동추천\n",
    "df = pd.read_csv('행동추천.csv')  \n",
    "if score >= 0:\n",
    "    print(random.choice(df.iloc[:, 0].dropna().tolist()))\n",
    "else:\n",
    "    print(random.choice(df.iloc[:, 4].dropna().tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
